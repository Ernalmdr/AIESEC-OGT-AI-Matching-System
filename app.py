import streamlit as st
import sys
import os
import urllib.parse
import PyPDF2
import pandas as pd
import random
import json
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer, util

from src.services.pdf_generator import PDFReportGenerator
# --- STREAMLIT SECRETS KÃ–PRÃœSÃœ ---
# Bu kod, Streamlit kasasÄ±ndaki ÅŸifreleri uygulamanÄ±n kullanabileceÄŸi hale getirir.
if hasattr(st, "secrets"):
    # 1. TÃ¼m ÅŸifreleri sisteme tanÄ±t
    for key, value in st.secrets.items():
        os.environ[key] = str(value)
    
    # 2. Google DosyasÄ±nÄ± (credentials.json) sanal olarak oluÅŸtur
    if "GOOGLE_CREDENTIALS" in st.secrets:
        with open("credentials.json", "w") as f:
            f.write(st.secrets["GOOGLE_CREDENTIALS"])
# ----------------------------------

# --- 1. AYARLAR ---
st.set_page_config(page_title="OGT AI Matcher", layout="wide", page_icon="ğŸ¤–")

current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

# Importlar
try:
    from src.repositories.podio_repo import PodioRepository
    from src.repositories.expa_repo import ExpaRepository
    from src.services.ai_matcher import AIMatcher
    from src.services.jd_scraper import JDScraper
    from src.repositories.google_sheets_repo import GoogleSheetsRepository
except ImportError as e:
    st.error(f"âš ï¸ Kritik Hata: Dosyalar bulunamadÄ±! ({e})")
    st.stop()

load_dotenv()

# --- YAPAY ZEKA MODELÄ°NÄ° YÃœKLE (Ã–NBELLEK) ---
@st.cache_resource
def load_embedding_model():
    # Bu model hem hÄ±zlÄ± hem de anlamsal iliÅŸkileri Ã§ok iyi yakalar
    return SentenceTransformer('all-MiniLM-L6-v2')
def main():
    st.title("ğŸ¤– AIESEC OGT Operasyon Paneli v2.1")

    # --- SESSION STATE ---
    if 'applicants' not in st.session_state: st.session_state['applicants'] = []
    if 'project_offset' not in st.session_state: st.session_state.project_offset = 0
    if 'filtered_projects_cache' not in st.session_state: st.session_state.filtered_projects_cache = []
    if 'ai_results_cache' not in st.session_state: st.session_state.ai_results_cache = {}

    # --- YAN MENÃœ ---
    st.sidebar.header("âš™ï¸ Veri KaynaklarÄ±")
    if st.sidebar.button("ğŸ§¹ SÄ±fÄ±rla"):
        st.session_state.clear()
        st.rerun()

    # BURASI GÃœNCELLENDÄ°: Yeni App ID ve View ID Geri Geldi
    app_id = st.sidebar.text_input("Podio App ID", value="23409870")
    view_id = st.sidebar.text_input("View ID (Ã–rn: Sign Up Listesi)",value="61478954",
                                    help="Podio'da filtrelediÄŸin listenin URL'sindeki son sayÄ±dÄ±r.")

    if st.sidebar.button("ğŸ“¦ AdaylarÄ± Ã‡ek"):
        with st.spinner("Podio'ya baÄŸlanÄ±lÄ±yor..."):
            try:
                repo = PodioRepository()
                # View ID varsa onu kullan, yoksa boÅŸ gÃ¶nder
                v_id = view_id if view_id.strip() else None
                apps = repo.fetch_applicants(app_id, view_id=v_id)
                st.session_state['applicants'] = apps
                st.sidebar.success(f"âœ… {len(apps)} aday yÃ¼klendi!")
            except Exception as e:
                st.sidebar.error(f"Hata: {e}")

    st.sidebar.divider()

    # --- YENÄ° FÄ°LTRELER ---
    st.sidebar.header("ğŸ¯ GeliÅŸmiÅŸ Filtreler")
    f_country = st.sidebar.text_input("ğŸŒ Ãœlke (Ã–rn: India)")
    f_field = st.sidebar.text_input("ğŸ’¼ Departman (Ã–rn: Marketing)")
    f_duration = st.sidebar.selectbox("â³ SÃ¼re", ["Farketmez", "KÄ±sa (Short)", "Orta (Medium)", "Uzun (Long)"])
    f_paid_only = st.sidebar.checkbox("ğŸ’° Sadece MaaÅŸlÄ± Projeler")

    # --- ANA EKRAN ---
    if st.session_state['applicants']:
        names = [a.full_name for a in st.session_state['applicants']]
        selected_name = st.selectbox("Aday SeÃ§:", names)
        if 'last_selected_candidate' not in st.session_state:
            st.session_state.last_selected_candidate = selected_name

        if st.session_state.last_selected_candidate != selected_name:
            # Aday deÄŸiÅŸtiÄŸi an hafÄ±zayÄ± ve ekranÄ± temizle
            st.session_state.ai_results_cache = {}
            st.session_state.filtered_projects_cache = []
            st.session_state.project_offset = 0
            st.session_state.last_selected_candidate = selected_name
            st.rerun()  # SayfayÄ± yenile
        ep = next((a for a in st.session_state['applicants'] if a.full_name == selected_name), None)

        if ep:
            # Aday KartÄ±
            c1, c2 = st.columns(2)
            c1.info(f"ğŸ‘¤ **{ep.full_name}**")
            c2.warning(f"ğŸ“ {ep.background or 'BÃ¶lÃ¼m Yok'}\n\nğŸ“§ {ep.email}")

            # CV YÃ¼kleme
            uploaded_file = st.file_uploader("ğŸ“„ CV YÃ¼kle (PDF)", type="pdf")
            cv_text = ""
            if uploaded_file:
                try:
                    pdf = PyPDF2.PdfReader(uploaded_file)
                    for p in pdf.pages: cv_text += p.extract_text()
                    st.caption("âœ… CV okundu.")
                except:
                    st.error("PDF HatasÄ±")

            st.divider()

            # Butonlar
            col_b1, col_b2 = st.columns(2)
            btn_start = col_b1.button("ğŸš€ EÅŸleÅŸmeleri Bul")
            btn_more = col_b2.button("ğŸ”„ Sonraki 3 Proje")

            # Servisler
            matcher = AIMatcher()
            expa = ExpaRepository()
            scraper = JDScraper()

            # 1. FÄ°LTRELEME & SIRALAMA
            if btn_start:
                st.session_state.project_offset = 0
                st.session_state.ai_results_cache = {}
                with st.spinner("ğŸ§  CV'den yetenekler ayrÄ±ÅŸtÄ±rÄ±lÄ±yor..."):
                    try:
                        # EÄŸer CV metni varsa AI'dan saf yetenekleri iste
                        if cv_text:
                            ai_keywords = matcher.extract_keywords_from_cv(cv_text)
                            st.caption(f"ğŸ¯ AI'nÄ±n BulduÄŸu Yetenekler: {', '.join(ai_keywords)}")
                        else:
                            # CV yoksa Podio verilerini kullan
                            ai_keywords = (ep.background + " " + " ".join(ep.skills)).lower().split()
                    except Exception as e:
                        st.error(f"AI Keyword HatasÄ±: {e}")
                        ai_keywords = []

                with st.spinner("EXPA'dan projeler taranÄ±yor..."):
                    try:
                        all_projects = expa.fetch_data()

                        # Filtreleme (Ãœlke & Departman)
                        filtered = []
                        for p in all_projects:
                            country_check = (p.country or "").lower()
                            if "turkey" in country_check or "tÃ¼rkiye" in country_check:
                                continue  # Bu projeyi atla, listeye ekleme
                            search_text = (p.title + " " + p.organisation + " " + getattr(p, 'home_lc', '')).lower()
                            if f_country and f_country.lower() not in search_text: continue
                            if f_field and f_field.lower() not in search_text: continue
                            filtered.append(p)

                        if not filtered:
                            st.error("âŒ Kriterlere uygun proje bulunamadÄ±.")
                            st.session_state.filtered_projects_cache = []
                        else:
                            # --- 1. MODELÄ° HAZIRLA ---
                            embedder = load_embedding_model()  # Modeli Ã§aÄŸÄ±r

                            # --- 2. VEKTÃ–R HESAPLAMA (SEMANTÄ°K ARAMA) ---
                            st.info("ğŸ§  Yapay Zeka, ilanlarÄ± anlamsal olarak analiz ediyor...")

                            # AdayÄ±n profilini metne Ã§evir
                            candidate_text = f"{ep.background} {' '.join(ep.skills)}"
                            # VektÃ¶r oluÅŸtur
                            candidate_embedding = embedder.encode(candidate_text, convert_to_tensor=True)

                            # TÃ¼m projelerin baÅŸlÄ±k ve aÃ§Ä±klamalarÄ±nÄ± vektÃ¶re Ã§evir (Toplu iÅŸlem)
                            project_texts = [f"{p.title} {p.organisation} {p.description[:300]}" for p in filtered]
                            project_embeddings = embedder.encode(project_texts, convert_to_tensor=True)

                            # Benzerlik skorlarÄ±nÄ± hesapla (Cosine Similarity)
                            # SonuÃ§ 0 ile 1 arasÄ±ndadÄ±r (0.85 = %85 Benzerlik)
                            cosine_scores = util.cos_sim(candidate_embedding, project_embeddings)[0]

                            # --- 3. HÄ°BRÄ°T PUANLAMA (VektÃ¶r + Kelime) ---
                            scored_projects = []

                            # Destekleyici anahtar kelimeler (Bonus puan iÃ§in)
                            keywords = (ep.background + " " + " ".join(ep.skills)).lower().split()

                            for i, p in enumerate(filtered):
                                final_score = 0

                                # A. VektÃ¶r PuanÄ± (Baz Puan)
                                # 0.1 - 1.0 arasÄ±ndaki sayÄ±yÄ± 100'lÃ¼k sisteme Ã§eviriyoruz.
                                vector_score = float(cosine_scores[i]) * 100
                                final_score += vector_score

                                # B. Kelime Bonusu (Eski YÃ¶ntem Destekli)
                                p_txt = (p.title + " " + p.organisation).lower()
                                for k in keywords:
                                    if len(k) > 3 and k in p_txt:
                                        final_score += 5  # Kelime geÃ§iyorsa ekstra 5 puan

                                # C. Rastgelelik (Ã‡eÅŸitlilik)
                                final_score += random.randint(0, 3)

                                # EÅŸik DeÄŸer (Ã‡ok alakasÄ±zlarÄ± elemek iÃ§in Ã¶rn: 20 puan altÄ±)
                                if final_score > 20:
                                    scored_projects.append((final_score, p))

                            # PuanÄ± yÃ¼ksekten dÃ¼ÅŸÃ¼ÄŸe sÄ±rala
                            scored_projects.sort(key=lambda x: x[0], reverse=True)

                            # Listeyi gÃ¼ncelle
                            st.session_state.filtered_projects_cache = [x[1] for x in scored_projects]

                            # KullanÄ±cÄ±ya bilgi ver
                            top_score = round(scored_projects[0][0], 1) if scored_projects else 0
                            st.success(f"ğŸš€ {len(filtered)} proje Yapay Zeka ile tarandÄ±! En yÃ¼ksek uyum: {top_score}")
                    except Exception as e:
                        st.error(f"Filtreleme HatasÄ±: {e}")

            # 2. SAYFALAMA
            if btn_more:
                if st.session_state.filtered_projects_cache:
                    st.session_state.project_offset += 3
                    if st.session_state.project_offset >= len(st.session_state.filtered_projects_cache):
                        st.warning("âš ï¸ Liste baÅŸa dÃ¶ndÃ¼.")
                        st.session_state.project_offset = 0

            # 3. ANALÄ°Z VE GÃ–STERÄ°M
            cache = st.session_state.filtered_projects_cache
            offset = st.session_state.project_offset

            if cache:
                batch = cache[offset: offset + 3]

                if batch:
                    st.info(f"ğŸ“‹ Analiz Ediliyor: {offset + 1} - {offset + len(batch)}")
                    batch_key = f"batch_{offset}"

                    if batch_key not in st.session_state.ai_results_cache:
                        with st.spinner("ğŸŒ Proje detaylarÄ± web'den Ã§ekiliyor ve AI analiz ediyor..."):
                            for p in batch:
                                if len(p.description) < 200 and p.link:
                                    try:
                                        full_desc = scraper.fetch_description(p.link)
                                        p.description = full_desc
                                    except:
                                        pass

                            results = matcher.generate_batch_report(ep, batch, cv_text)
                            st.session_state.ai_results_cache[batch_key] = results
                    else:
                        results = st.session_state.ai_results_cache[batch_key]

                    # SonuÃ§larÄ± Bas
                    if results:
                        for i, res in enumerate(results):
                            try:
                                p_idx = res.get('project_index', i)
                                p = batch[p_idx] if p_idx < len(batch) else batch[i]

                                with st.expander(f"ğŸ“Œ {p.title} - {p.organisation} (Skor: {res.get('score', 0)})",
                                                 expanded=True):
                                    t1, t2 = st.tabs(["ğŸ§  Analiz", "ğŸ’¬ Aksiyon"])

                                    with t1:
                                        st.markdown("### ğŸ§ Teknik Uygunluk Analizi")
                                        st.info(res.get('suitability_analysis', 'Analiz yapÄ±lamadÄ±.'))

                                        # --- 2. SATIÅ TAKTÄ°KLERÄ° ---
                                        st.markdown("### ğŸ¯ SatÄ±ÅŸ Stratejisi")
                                        st.success(f"**NasÄ±l SunmalÄ±sÄ±n:** {res.get('sales_pitch', '')}")

                                        st.markdown("### ğŸ¥Š Ä°kna KozlarÄ± (Pain Points)")
                                        st.warning(res.get('pain_points', ''))
                                        with st.popover("ğŸ“„ Ä°ÅŸ TanÄ±mÄ± DetayÄ±"):
                                            st.write(p.description)

                                    with t2:
                                        # WhatsApp
                                        msg = res.get('whatsapp_msg', '')
                                        st.text_area("Mesaj TaslaÄŸÄ±:", value=msg, height=100)
                                        encoded_msg = urllib.parse.quote(msg)
                                        phone_num = getattr(ep, 'phone', '').replace(" ", "").replace("+", "")
                                        st.link_button("ğŸ“± WhatsApp", f"https://wa.me/{phone_num}?text={encoded_msg}")

                                        # Podio + Sheets Butonu
                                        st.divider()
                                        if st.button(f"ğŸ“ Podio & Tabloya Kaydet", key=f"btn_podio_{i}"):
                                            with st.spinner("Ä°ÅŸleniyor..."):
                                                # 1. Podio Yorum (Aktif)
                                                try:
                                                    comment_body = f"""
                                                    [AI ANALÄ°ZÄ° - {p.title}]
                                                    âœ… Uyum Skoru: {res.get('score')}/100
                                                    ğŸ’¡ Strateji: {res.get('sales_pitch')}
                                                    ğŸ”— Link: https://aiesec.org/opportunity/{p.op_id}
                                                    """
                                                    repo_podio = PodioRepository()
                                                    repo_podio.add_comment(ep.ep_id, comment_body)
                                                    st.toast("âœ… Podio yorumu eklendi!")
                                                except Exception as e:
                                                    st.error(f"Podio HatasÄ±: {e}")

                                                # 2. Google Sheets (Aktif)
                                                try:
                                                    sheets = GoogleSheetsRepository()
                                                    sheets.log_match(
                                                        "OGT_Analiz_Loglari",
                                                        ep.full_name, p.title, p.organisation, p.country,
                                                        res.get('score'), res.get('sales_pitch')
                                                    )
                                                    st.toast("âœ… Tabloya iÅŸlendi!")
                                                except Exception as e:
                                                    st.error(f"Sheet HatasÄ±: {e}")

                                        st.divider()
                                        # --- PDF RAPOR BUTONU ---
                                        if st.button("ğŸ“„ PDF Raporu Ä°ndir", key=f"btn_pdf_{i}"):
                                            pdf_gen = PDFReportGenerator()
                                            pdf_file = pdf_gen.create_report(ep.full_name, p, res)

                                            with open(pdf_file, "rb") as f:
                                                st.download_button(
                                                    label="ğŸ“¥ DosyayÄ± BilgisayarÄ±na Ä°ndir",
                                                    data=f,
                                                    file_name=pdf_file,
                                                    mime="application/pdf"
                                                )

                            except Exception as e:
                                st.error(f"GÃ¶sterim HatasÄ±: {e}")

                        # CSV Ä°ndirme
                        st.divider()
                        st.subheader("ğŸ’¾ Raporlama")
                        report_data = []
                        for res in results:
                            p_idx = res.get('project_index', 0)
                            p_obj = batch[p_idx] if p_idx < len(batch) else batch[0]
                            report_data.append({
                                "Aday": ep.full_name,
                                "Proje": p_obj.title,
                                "Skor": res.get('score'),
                                "Strateji": res.get('sales_pitch')
                            })
                        if report_data:
                            df = pd.DataFrame(report_data)
                            csv = df.to_csv(index=False).encode('utf-8-sig')
                            st.download_button("ğŸ“¥ Ä°ndir (CSV)", data=csv, file_name="analiz.csv", mime="text/csv")

    else:
        st.info("ğŸ‘ˆ Podio ID ve View ID (Opsiyonel) girip 'AdaylarÄ± Ã‡ek' butonuna basÄ±n.")


if __name__ == "__main__":
    main()
